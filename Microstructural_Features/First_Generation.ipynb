{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c72b3c4",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "> **Underlying Literature**: The following module was inspired by the ideas put forward in Chapter 19, Section 3 of [Advances in Financial Machine Learning](https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086) by Marcos Lopez de Prado\n",
    "\n",
    "In this notebook, we showcase how to properly use the functions belonging to the First Generation Models of our Microstructural Features module.\n",
    "\n",
    "We will first apply the Tick rule to our data set in in order to classify our trades as either sell-initiated or buy-initiated. Then, we will show how simple it is to use our feature transformation functions to produce  valuable features to be used in an ML model. Finally, we’ll showcase how to generate all of the transformations stored in this module by using one function call and providing a lookback period to generate these features on a rolling basis\n",
    "\n",
    "### Table of Contents\n",
    "- [The Tick Rule](#tick)\n",
    "- [The Roll Model](#roll)\n",
    "- [Feature Transformations:](#features)\n",
    "    - [Fractional Differentiation](#frac_diff)\n",
    "    - [Wald-Wolfowitz Runs Randomness](#wald_wolf)\n",
    "    - [Entropy Measures](#entropy)\n",
    "- [The Feature Matrix](#matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "906f14da",
   "metadata": {},
   "source": [
    "Before starting, we must first import our tick data from the sample data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4321fdf7-8f1c-46d9-98b3-0b85acd555d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "\n",
    "from mlfinlab.microstructural_features import first_generation as first_gen \n",
    "from mlfinlab.microstructural_features import entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e93cc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2015-01-01 23:16:58.834    2058.75\n",
       "2015-01-02 00:36:33.094    2058.25\n",
       "2015-01-02 01:54:08.770    2061.00\n",
       "2015-01-02 04:28:09.015    2062.50\n",
       "2015-01-02 06:57:53.850    2063.00\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the tick data and only storing the closing price\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/hudson-and-thames/example-data/main/tick_bars.csv\"\n",
    "tick_prices = pd.read_csv(url, index_col=0)['close']\n",
    "\n",
    "# Previewing the data\n",
    "tick_prices.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bf8a291",
   "metadata": {},
   "source": [
    "## The Tick Rule <a class=\"anchor\" id=\"tick\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04f6b883",
   "metadata": {},
   "source": [
    "The Tick Rule is an algorithm used to determine a trade’s aggressor side. A buy-initiated trade is labeled (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69d4ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2015-01-01 23:16:58.834    1.0\n",
       "2015-01-02 00:36:33.094   -1.0\n",
       "2015-01-02 01:54:08.770    1.0\n",
       "2015-01-02 04:28:09.015    1.0\n",
       "2015-01-02 06:57:53.850    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating trade classifications for our tick data\n",
    "tick_classifications = first_gen.tick_rule(prices = tick_prices)\n",
    "\n",
    "# Previewing the tick classifications\n",
    "tick_classifications.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea42dfb6",
   "metadata": {},
   "source": [
    "## The Roll Model <a class=\"anchor\" id=\"roll\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06cbbd35",
   "metadata": {},
   "source": [
    "The Roll Model (1984) provides market microstructure model that aims at estimating the effective bid-ask spread of a security from observed transaction prices. That said, the Roll model does not include any information on the underlying bid-ask price quotes and order flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe78d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36960456437467826"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Roll spread of the security based on the tick data\n",
    "spread = first_gen.roll_spread(prices = tick_prices)\n",
    "\n",
    "# Previewing the Roll spread\n",
    "spread"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cd977df",
   "metadata": {},
   "source": [
    "## Feature Transformations <a class=\"anchor\" id=\"features\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48ae13e5",
   "metadata": {},
   "source": [
    "There are many transformations that can be applied to the trade classifications yielded by the Tick Rule that make for interesting feature inputs to an ML model. The transformations contained in this module include the Wald-Wolfowitz Runs test to the classification series to determine how random the classifications are, fractional differencing of the classification series to achieve stationarity while simultaneously preserving a high degree of information, and various entropy measures that determine the amount of information contained in the classification sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc11f2ec",
   "metadata": {},
   "source": [
    "### Fractional Differentiation <a class=\"anchor\" id=\"frac_diff\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b570973",
   "metadata": {},
   "source": [
    "The key to successfully using the `fractional_differencing` function is to experiment with different differencing values and threshold values. If the result you are obtaining is not stationary enough (i.e. the p-value of the ADF test is too high) then you should increase the differencing amount. If the result you are obtaining is not correlated enough to the original series (i.e. the Pearson r-value is too low) then you should decrease the differencing amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c8f3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'series': date_time\n",
       " 2015-01-01 23:16:58.834          NaN\n",
       " 2015-01-02 00:36:33.094          NaN\n",
       " 2015-01-02 01:54:08.770          NaN\n",
       " 2015-01-02 04:28:09.015          NaN\n",
       " 2015-01-02 06:57:53.850          NaN\n",
       "                              ...    \n",
       " 2016-12-30 20:58:37.916    86.773701\n",
       " 2016-12-30 20:59:30.587    87.280432\n",
       " 2016-12-30 20:59:53.515    85.685898\n",
       " 2016-12-30 21:00:21.588    84.951707\n",
       " 2016-12-30 21:08:09.245    84.418463\n",
       " Name: close, Length: 41123, dtype: float64,\n",
       " 'adf_p_value': 0.05,\n",
       " 'pearson_r_value': 0.999}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the fractionally differenced series and it's associated, relevant test statistics\n",
    "fractionally_differenced_classifications = first_gen.fractional_differencing(\n",
    "    classifications = tick_classifications,\n",
    "    differencing_amount = 0.453,\n",
    "    threshold = 0.01)\n",
    "\n",
    "# Previewing the output\n",
    "fractionally_differenced_classifications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "832e77d5",
   "metadata": {},
   "source": [
    "The `fractional_differencing` function returns a dictionary that contains the differenced series, the p-value of an ADF test, and the r value of a Pearson test. These are all stored in a dictionary and can be accessed using the appropriate keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49183d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the ADF p-value\n",
    "fractionally_differenced_classifications['adf_p_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aefe602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the Pearson r value\n",
    "fractionally_differenced_classifications['pearson_r_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080b983a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_time\n",
       "2015-01-01 23:16:58.834          NaN\n",
       "2015-01-02 00:36:33.094          NaN\n",
       "2015-01-02 01:54:08.770          NaN\n",
       "2015-01-02 04:28:09.015          NaN\n",
       "2015-01-02 06:57:53.850          NaN\n",
       "                             ...    \n",
       "2016-12-30 20:58:37.916    86.773701\n",
       "2016-12-30 20:59:30.587    87.280432\n",
       "2016-12-30 20:59:53.515    85.685898\n",
       "2016-12-30 21:00:21.588    84.951707\n",
       "2016-12-30 21:08:09.245    84.418463\n",
       "Name: close, Length: 41123, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the fractionally differenced series\n",
    "fractionally_differenced_classifications['series']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b1e4dc7",
   "metadata": {},
   "source": [
    "### Wald-Wolfowitz Runs Randomness <a class=\"anchor\" id=\"wald_wolf\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff39d40d",
   "metadata": {},
   "source": [
    "The `wald_wolfowitz_runs_test` function returns the p-value of a Wald-Wolfowitz runs statistical test. The lower the p-value, the more likely the ordering of the runs is not random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd7a0014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.494397640453383e-35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating the p-value of the Wald-Wolfowitz runs test\n",
    "wald_wolfowitz_randomness = first_gen.wald_wolfowitz_runs_test(classifications = tick_classifications)\n",
    "\n",
    "# Previewing the p-value\n",
    "wald_wolfowitz_randomness"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d2e8fa",
   "metadata": {},
   "source": [
    "### Entropy Measures <a class=\"anchor\" id=\"entropy\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "738045f1",
   "metadata": {},
   "source": [
    "Entropy measures in financial sciences aim to discern how much information is contained in a given time series. That said, when markets are not perfect, prices are formed with partial information. As a result, entropy measures are helpful in determining just how much useful information is contained in said price signals."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d5d9b3a",
   "metadata": {},
   "source": [
    "####  Shannon Entropy\n",
    "\n",
    "Claude Shannon is credited with having one of the first conceptualizations of entropy in 1948, which he defined as the\n",
    "average amount of information produced by a stationary source of data. More robustly defined, entropy is the smallest\n",
    "number of bits per character required to describe a message in a uniquely decodable way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b95a35ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9895875212220555"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Shannon entropy of a subset of the tick classifications\n",
    "shannon_entropy = entropy.get_shannon_entropy(message = tick_classifications[:100])\n",
    "\n",
    "# Previewing the Shannon entropy\n",
    "shannon_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "034f4748",
   "metadata": {},
   "source": [
    "#### Pug-In Entropy\n",
    "\n",
    "Gao et al. (2008) built on the work done by Shannon by conceptualizing the Plug-in measure of entropy, also known as\n",
    "the maximum likelihood estimator of entropy. Given a data sequence $x_{1}^{n}$, comprising the string of values starting in position 1 and ending in position\n",
    ":$n$, we can form a dictionary of all words of length $w < n$ in that sequence: $A^w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac025019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875257101057102"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Plug-in entropy of a subset of the tick classifications\n",
    "plug_in_entropy = entropy.get_plug_in_entropy(message = tick_classifications[:100])\n",
    "\n",
    "# Previewing the Plug-in entropy\n",
    "plug_in_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "985ed467",
   "metadata": {},
   "source": [
    "#### Lempel-Ziv Entropy \n",
    "\n",
    "Similar to Shannon entropy, Abraham Lempel and Jacob Ziv proposed in 1978 that entropy be treated as a measure of\n",
    "complexity. Intuitively, a complex sequence contains more information than a regular (predictable) sequence. Based on\n",
    "this idea, the Lempel-Ziv (LZ) algorithm decomposes a message into a number of non-redundant substrings. LZ entropy builds on this idea by dividing the number of non-redundant substrings by the length of the\n",
    "original message. The intuition here is that complex messages have high entropy, which will require large dictionaries\n",
    "of substrings relative to the length of the original message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e3e5e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Lempel-Ziv entropy of a subset of the tick classifications\n",
    "lempel_ziv_entropy = entropy.get_lempel_ziv_entropy(message = tick_classifications[:100])\n",
    "\n",
    "# Previewing the Lempel-Ziv entropy\n",
    "lempel_ziv_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b364f69",
   "metadata": {},
   "source": [
    "#### Kontoyiannis Entropy\n",
    "\n",
    "In 1998 Kontoyiannis attempted to make more efficient use of the information available in a message by taking advantage of\n",
    "a technique known as length matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "100b2aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8681763656863827"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the Kontoyiannis entropy of a subset of the tick classifications\n",
    "kontoyiannis_entropy = entropy.get_konto_entropy(message = tick_classifications[:100])\n",
    "\n",
    "# Previewing the Konto entropy\n",
    "kontoyiannis_entropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "352d4d25",
   "metadata": {},
   "source": [
    "Users may be wondering why some of the entropy functions are yielding values greater than 1. A comprehensive explanation of why this is occurring can be found in the StackExchange thread named [Why am I getting information entropy greater than 1?](https://stats.stackexchange.com/questions/95261/why-am-i-getting-information-entropy-greater-than-1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beddc610",
   "metadata": {},
   "source": [
    "The short explanation is that we are calculating our entropy measures using a log function with a base of 2, which has a maximum value that is greater than 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62cf5801",
   "metadata": {},
   "source": [
    "## The Feature Matrix <a class=\"anchor\" id=\"matrix\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11e21dc7",
   "metadata": {},
   "source": [
    "Finally, we show the easiest way of taking advantage of the functions in this module, which is to call the `generate_feature_matrix` function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "060beb3e",
   "metadata": {},
   "source": [
    "The user must provide the tick classifications generated by the tick rule and a `lookback_period`, which is the window of entries that the user wants each of the feature transformation functions included in this module to be computed over on a rolling basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "857fe33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll_spread</th>\n",
       "      <th>fractional_difference</th>\n",
       "      <th>wald_wolfowitz_p_value</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>lempel_ziv_entropy</th>\n",
       "      <th>plug_in_entropy</th>\n",
       "      <th>konto_entropy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:21:26.264</th>\n",
       "      <td>1.802776</td>\n",
       "      <td>1.023294</td>\n",
       "      <td>0.662521</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.764160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:53:13.935</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285212</td>\n",
       "      <td>0.414216</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.646241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:20:26.945</th>\n",
       "      <td>2.061553</td>\n",
       "      <td>-0.898121</td>\n",
       "      <td>0.414216</td>\n",
       "      <td>0.721928</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 11:05:56.143</th>\n",
       "      <td>1.322876</td>\n",
       "      <td>0.652724</td>\n",
       "      <td>0.512691</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.896241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 11:45:14.081</th>\n",
       "      <td>3.763863</td>\n",
       "      <td>-0.621354</td>\n",
       "      <td>0.512691</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30 20:58:37.916</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>86.773701</td>\n",
       "      <td>0.662521</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30 20:59:30.587</th>\n",
       "      <td>1.224745</td>\n",
       "      <td>87.280432</td>\n",
       "      <td>0.126630</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30 20:59:53.515</th>\n",
       "      <td>1.040833</td>\n",
       "      <td>85.685898</td>\n",
       "      <td>0.662521</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.764160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30 21:00:21.588</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.951707</td>\n",
       "      <td>0.126630</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.811278</td>\n",
       "      <td>0.646241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30 21:08:09.245</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.418463</td>\n",
       "      <td>0.126630</td>\n",
       "      <td>0.970951</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37883 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         roll_spread  fractional_difference   \n",
       "date_time                                                     \n",
       "2015-01-02 09:21:26.264     1.802776               1.023294  \\\n",
       "2015-01-02 09:53:13.935     0.000000              -0.285212   \n",
       "2015-01-02 10:20:26.945     2.061553              -0.898121   \n",
       "2015-01-02 11:05:56.143     1.322876               0.652724   \n",
       "2015-01-02 11:45:14.081     3.763863              -0.621354   \n",
       "...                              ...                    ...   \n",
       "2016-12-30 20:58:37.916     0.000000              86.773701   \n",
       "2016-12-30 20:59:30.587     1.224745              87.280432   \n",
       "2016-12-30 20:59:53.515     1.040833              85.685898   \n",
       "2016-12-30 21:00:21.588     0.000000              84.951707   \n",
       "2016-12-30 21:08:09.245     0.000000              84.418463   \n",
       "\n",
       "                         wald_wolfowitz_p_value  shannon_entropy   \n",
       "date_time                                                          \n",
       "2015-01-02 09:21:26.264                0.662521         0.970951  \\\n",
       "2015-01-02 09:53:13.935                0.414216         0.721928   \n",
       "2015-01-02 10:20:26.945                0.414216         0.721928   \n",
       "2015-01-02 11:05:56.143                0.512691         0.970951   \n",
       "2015-01-02 11:45:14.081                0.512691         0.970951   \n",
       "...                                         ...              ...   \n",
       "2016-12-30 20:58:37.916                0.662521         0.970951   \n",
       "2016-12-30 20:59:30.587                0.126630         0.970951   \n",
       "2016-12-30 20:59:53.515                0.662521         0.970951   \n",
       "2016-12-30 21:00:21.588                0.126630         0.970951   \n",
       "2016-12-30 21:08:09.245                0.126630         0.970951   \n",
       "\n",
       "                         lempel_ziv_entropy  plug_in_entropy  konto_entropy  \n",
       "date_time                                                                    \n",
       "2015-01-02 09:21:26.264                 0.6         0.811278       0.764160  \n",
       "2015-01-02 09:53:13.935                 0.6         0.811278       0.646241  \n",
       "2015-01-02 10:20:26.945                 0.6         0.811278       1.000000  \n",
       "2015-01-02 11:05:56.143                 0.6         0.811278       0.896241  \n",
       "2015-01-02 11:45:14.081                 0.6         1.000000       0.896241  \n",
       "...                                     ...              ...            ...  \n",
       "2016-12-30 20:58:37.916                 0.6         1.000000       0.896241  \n",
       "2016-12-30 20:59:30.587                 0.6         1.000000       1.000000  \n",
       "2016-12-30 20:59:53.515                 0.6         0.811278       0.764160  \n",
       "2016-12-30 21:00:21.588                 0.6         0.811278       0.646241  \n",
       "2016-12-30 21:08:09.245                 0.6         1.000000       1.000000  \n",
       "\n",
       "[37883 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating our feature matrix\n",
    "feature_matrix = first_gen.generate_feature_matrix(\n",
    "    tick_prices = tick_prices,\n",
    "    lookback_period = 5,\n",
    "    fractional_differencing_amount = 0.453,\n",
    "    fractional_differencing_threshold = 0.01)\n",
    "\n",
    "# Previewing the feature matrix\n",
    "feature_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc713692-6260-417c-8c7a-a9b92026fea8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook describes functions belonging to the First Generation Models of the Microstructural Features Module from the MlFinLab package.\n",
    "\n",
    "These tools have been originally presented in the book \"Advances in Financial Machine Learning\" by Marcos Lopez De Prado (https://www.wiley.com/en-us/Advances+in+Financial+Machine+Learning-p-9781119482086).\n",
    "\n",
    "Key takeaways from the notebook:\n",
    "\n",
    "* The Tick Rule is an algorithm used to determine a trade’s aggressor side.\n",
    "\n",
    "* The Roll Model provides market microstructure model for estimating the effective bid-ask spread of a security.\n",
    "\n",
    "* The Wald-Wolfowitz Runs test is used to determine how random the classifications are.\n",
    "\n",
    "* Fractional differencing of the classification series is used to achieve stationarity while simultaneously preserving a high degree of information.\n",
    "\n",
    "* Various entropy measures determine the amount of information contained in the classification sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b3e408b-d4ed-46b0-9499-00782886df77",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "* Lopez de Prado, M. (2018) Advances in Financial Machine Learning. New York, NY: John Wiley & Sons."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
